{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c44715d-ce02-4a9f-8f9d-138ea8ae4b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9538243-ad7c-45ab-8b11-d479062f97d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a717c54-13b3-4c6f-bc15-77cc1721ee8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbf37966-5bef-45f3-bb08-132d8ea35160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (11): Concat()\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (14): Concat()\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat()\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat()\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3499b5b-f7b3-454f-b039-76dff21952c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = next(model.parameters()).device\n",
    "print(f\"The model is on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a0d15-af31-45e3-96be-1ffdcd00bba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.86 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.83  Python-3.12.5 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=train(two classes refined)/weights/best.pt, data=dataset/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=runs, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6.25M/6.25M [00:00<00:00, 9.00MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\yolo\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:268: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\Table Detection\\dataset\\train\\labels... 867 images, 30 backgro\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\Table Detection\\dataset\\train\\labels.cache\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=\"dataset/data.yaml\", epochs=100, imgsz=640,device='cuda',project=\"runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae7ff75a-83e6-49e5-b212-123a4d5b53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"Table Detection/train(two classes refined)/weights/best.pt\")#change the path to the generated model at the end of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e534e1-492d-4d35-a9b4-7cf9684cc454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.83  Python-3.12.5 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\dataset\\val\\labels.cache... 169 images, 10 backgrounds, 0 corrup\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179        279      0.924      0.943      0.978      0.948\n",
      "      borderless_table        139        229      0.958      0.926       0.98      0.924\n",
      "          border_table         30         50       0.89       0.96      0.975      0.972\n",
      "Speed: 0.9ms preprocess, 6.4ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\HP\\Desktop\\Extras\\PythonML\\runs\\detect\\val6\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0.92365,     0.97168])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map  # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76788084-9f2e-462a-b565-1014d012b9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\ada.jpeg: 384x640 (no detections), 63.0ms\n",
      "Speed: 166.1ms preprocess, 63.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model('ada.jpeg')  # Process the image with the model #change the name into the your image file\n",
    "\n",
    "# Process and display the filtered results\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # Display to screen\n",
    "    result.save(filename=\"result_tables.jpg\")  # Save result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e487d-8514-412a-ae7f-5675a0631056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model(['bbbb.png'])  # return a list of Results objects\n",
    "\n",
    "# # Process results list\n",
    "# for result in results:\n",
    "#     boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "#     masks = result.masks  # Masks object for segmentation masks outputs\n",
    "#     keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "#     probs = result.probs  # Probs object for classification outputs\n",
    "#     obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "#     result.show()  # display to screen\n",
    "#     result.save(filename=\"result.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25a60670-1c78-4d24-96cd-62cd3d143446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\1.png: 640x480 2 border_tables, 46.4ms\n",
      "Speed: 0.0ms preprocess, 46.4ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\10.png: 640x608 2 borderless_tables, 90.0ms\n",
      "Speed: 44.9ms preprocess, 90.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\11.png: 640x576 3 border_tables, 69.6ms\n",
      "Speed: 14.6ms preprocess, 69.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\12.png: 640x544 8 border_tables, 69.9ms\n",
      "Speed: 80.0ms preprocess, 69.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\13.png: 640x480 1 border_table, 20.3ms\n",
      "Speed: 17.1ms preprocess, 20.3ms inference, 10.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\14.png: 640x480 1 borderless_table, 1 border_table, 62.9ms\n",
      "Speed: 22.0ms preprocess, 62.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\15.png: 640x512 2 border_tables, 56.1ms\n",
      "Speed: 19.6ms preprocess, 56.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\16.png: 640x448 1 border_table, 63.5ms\n",
      "Speed: 41.1ms preprocess, 63.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\17.png: 640x512 1 border_table, 80.8ms\n",
      "Speed: 45.1ms preprocess, 80.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\18.png: 640x480 1 border_table, 52.9ms\n",
      "Speed: 5.9ms preprocess, 52.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\19.png: 640x480 1 border_table, 93.8ms\n",
      "Speed: 5.7ms preprocess, 93.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\2.png: 640x640 4 borderless_tables, 75.3ms\n",
      "Speed: 92.7ms preprocess, 75.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\20.png: 640x512 1 border_table, 30.0ms\n",
      "Speed: 39.4ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\3.png: 640x480 2 borderless_tables, 62.8ms\n",
      "Speed: 71.6ms preprocess, 62.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\4.png: 640x480 2 borderless_tables, 39.4ms\n",
      "Speed: 7.1ms preprocess, 39.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\5.png: 640x480 2 borderless_tables, 40.3ms\n",
      "Speed: 6.0ms preprocess, 40.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\6.png: 640x480 2 border_tables, 48.5ms\n",
      "Speed: 44.0ms preprocess, 48.5ms inference, 8.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\7.png: 640x512 4 border_tables, 46.3ms\n",
      "Speed: 60.9ms preprocess, 46.3ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\8.png: 640x512 1 borderless_table, 62.7ms\n",
      "Speed: 71.8ms preprocess, 62.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 C:\\Users\\HP\\Desktop\\Extras\\PythonML\\yolo\\testdata\\9.png: 640x544 3 borderless_tables, 62.0ms\n",
      "Speed: 73.3ms preprocess, 62.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Table detection and cropping complete.\n"
     ]
    }
   ],
   "source": [
    "#crop detected tables\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO(\"Table Detection/train(two classes refined)/weights/best.pt\")\n",
    "\n",
    "# Directory where your images are stored\n",
    "image_folder = \"testdata\"  # Replace with your folder containing the 20 images\n",
    "output_folder = \"cropped_images2\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each image in the folder\n",
    "for img_name in os.listdir(image_folder):\n",
    "    if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(image_folder, img_name)\n",
    "        \n",
    "        # Run the model on the image\n",
    "        results = model(img_path)\n",
    "\n",
    "        # Process results and save the cropped tables\n",
    "        for result in results:\n",
    "            boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "            \n",
    "            # Load the image with PIL\n",
    "            image = Image.open(img_path)\n",
    "\n",
    "            if image.mode == 'RGBA':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            # Iterate over each detected box\n",
    "            for i, box in enumerate(boxes):\n",
    "                # Get the bounding box coordinates\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()  # Convert to numpy array\n",
    "\n",
    "                # Crop the detected table from the image\n",
    "                cropped_img = image.crop((x1, y1, x2, y2))\n",
    "\n",
    "                # Save the cropped image in the output folder\n",
    "                cropped_img_name = f\"{os.path.splitext(img_name)[0]}_table_{i+1}.jpg\"\n",
    "                cropped_img_path = os.path.join(output_folder, cropped_img_name)\n",
    "                cropped_img.save(cropped_img_path)\n",
    "\n",
    "            # Optionally, show or save the annotated image\n",
    "            result.show()  # To display the image with bounding boxes\n",
    "            result.save(filename=f\"annotated_{img_name}\")  # To save the annotated image\n",
    "\n",
    "print(\"Table detection and cropping complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6947cf9-c0bb-4f40-8462-8d005d95f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detection through webcam\n",
    "# import cv2\n",
    "# from ultralytics import YOLO\n",
    "\n",
    "# # Load the YOLO model\n",
    "# model = YOLO('runs/detect/train/weights/best.pt')  # Replace with your model file\n",
    "\n",
    "# # Initialize webcam\n",
    "# cap = cv2.VideoCapture(0)  # Use 0 for the default webcam\n",
    "\n",
    "# # Optionally set webcam resolution\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     if not ret:\n",
    "#         print(\"Failed to grab frame\")\n",
    "#         break\n",
    "\n",
    "#     # Run YOLO model on the captured frame\n",
    "#     results = model(frame)\n",
    "\n",
    "#     # Process and show the results\n",
    "#     for result in results:\n",
    "#         result.show()  # Display the processed frame with detections\n",
    "\n",
    "#     # Display the original frame\n",
    "#     cv2.imshow('YOLO Real-Time Detection', frame)\n",
    "\n",
    "#     # Exit loop on 'q' key press\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the webcam and close all OpenCV windows\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707235cc-aa46-4bba-8cc0-13d81e069a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
